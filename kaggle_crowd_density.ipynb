{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea9cf101",
   "metadata": {},
   "source": [
    "# Crowd Density Detection Project - Kaggle Setup Guide\n",
    "\n",
    "This notebook provides a detailed guide for uploading and running the Crowd Density Detection project on Kaggle. We'll go through each step from preparing the files to running the model on Kaggle's infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023fe6ba",
   "metadata": {},
   "source": [
    "## 1. Project Structure\n",
    "\n",
    "First, let's understand our project structure:\n",
    "\n",
    "```\n",
    "Crowd_Density_Detection/\n",
    "├── images.npy          # Image data\n",
    "├── requirements.txt    # Project dependencies\n",
    "├── test_model.py      # Testing script\n",
    "└── Libs/              # Project libraries\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bca0123",
   "metadata": {},
   "source": [
    "## 2. Local Preparation Steps\n",
    "\n",
    "1. Install Kaggle API:\n",
    "```bash\n",
    "pip install kaggle\n",
    "```\n",
    "\n",
    "2. Set up Kaggle credentials:\n",
    "- Go to kaggle.com → Account → Create API Token\n",
    "- Download kaggle.json\n",
    "- Create .kaggle directory and move the file:\n",
    "```bash\n",
    "mkdir -p ~/.kaggle\n",
    "mv kaggle.json ~/.kaggle/\n",
    "chmod 600 ~/.kaggle/kaggle.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63764531",
   "metadata": {},
   "source": [
    "## 3. Prepare Dataset for Upload\n",
    "\n",
    "1. Create a new directory for Kaggle upload\n",
    "2. Organize files in the correct structure\n",
    "3. Create dataset metadata file\n",
    "\n",
    "Run the following commands in your terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15dde75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create upload directory\n",
    "!mkdir -p crowd_density_dataset\n",
    "\n",
    "# Copy project files\n",
    "!cp -r Libs crowd_density_dataset/\n",
    "!cp images.npy crowd_density_dataset/\n",
    "!cp requirements.txt crowd_density_dataset/\n",
    "!cp test_model.py crowd_density_dataset/\n",
    "\n",
    "# Create dataset metadata\n",
    "!echo '{\n",
    "    \"title\": \"Crowd Density Detection Dataset\",\n",
    "    \"id\": \"yourusername/crowd-density-detection\",\n",
    "    \"licenses\": [{\"name\": \"CC0-1.0\"}]\n",
    "}' > crowd_density_dataset/dataset-metadata.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5fe1b3",
   "metadata": {},
   "source": [
    "## 4. Upload to Kaggle\n",
    "\n",
    "Use the Kaggle API to create and upload your dataset:\n",
    "\n",
    "```bash\n",
    "kaggle datasets create -p crowd_density_dataset\n",
    "```\n",
    "\n",
    "After upload, your dataset will be available at: https://www.kaggle.com/yourusername/crowd-density-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef498865",
   "metadata": {},
   "source": [
    "## 5. Create Kaggle Notebook\n",
    "\n",
    "1. Go to your dataset page on Kaggle\n",
    "2. Click 'New Notebook'\n",
    "3. In the notebook settings:\n",
    "   - Enable GPU accelerator\n",
    "   - Set Internet on if needed\n",
    "   - Choose Python as the language\n",
    "\n",
    "Add the following code to your Kaggle notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0857c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -r ../input/crowd-density-detection/requirements.txt\n",
    "\n",
    "# Import necessary libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Add project libraries to path\n",
    "sys.path.append('../input/crowd-density-detection/Libs')\n",
    "\n",
    "# Load the image data\n",
    "images = np.load('../input/crowd-density-detection/images.npy')\n",
    "print(f\"Loaded images shape: {images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e50893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and run the test model\n",
    "from test_model import test_model\n",
    "\n",
    "# Configure GPU memory growth to avoid memory issues\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Run the model\n",
    "test_model(images)\n",
    "\n",
    "print(\"Model testing completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fdc363",
   "metadata": {},
   "source": [
    "## 6. Tips and Troubleshooting\n",
    "\n",
    "1. Memory Management\n",
    "   - If you encounter memory issues, try processing images in batches\n",
    "   - Use GPU memory growth configuration as shown above\n",
    "\n",
    "2. Common Issues:\n",
    "   - If packages fail to install, check versions in requirements.txt\n",
    "   - If imports fail, verify the sys.path addition\n",
    "   - For GPU errors, ensure GPU accelerator is enabled\n",
    "\n",
    "3. Performance Optimization:\n",
    "   - Use tf.data.Dataset for efficient data loading\n",
    "   - Enable mixed precision training if needed\n",
    "   - Monitor GPU utilization in Kaggle's metrics\n",
    "\n",
    "4. Saving Results:\n",
    "   - Use Kaggle's output directory for saving results\n",
    "   - Commit notebook regularly to save progress"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
